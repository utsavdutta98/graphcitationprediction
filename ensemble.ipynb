{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ensemble.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MS5zRHlKvkeb","executionInfo":{"status":"ok","timestamp":1639004821803,"user_tz":300,"elapsed":488,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_colwidth', 0)\n","import matplotlib.pyplot as plt\n","import itertools\n","import random\n","import tqdm as tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":21,"outputs":[]},{"cell_type":"code","source":["!pip install stellargraph\n","import stellargraph as sg\n","from stellargraph.data import EdgeSplitter\n","from stellargraph.mapper import GraphSAGELinkGenerator\n","from stellargraph.layer import GraphSAGE, HinSAGE, link_classification\n","import pandas as pd\n","import itertools\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn import preprocessing, feature_extraction, model_selection\n","import numpy as np\n","from stellargraph import globalvar\n","from stellargraph import datasets\n","from IPython.display import display, HTML\n","import nltk\n","nltk.download('punkt')\n","%matplotlib inline"],"metadata":{"id":"STql7-uW47BR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639004826889,"user_tz":300,"elapsed":3993,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"0e9a5791-12c4-428e-c18f-589019a41ef6"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: stellargraph in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.2.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.4.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.6.3)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.6.0)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.0.1)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.1.5)\n","Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.7.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (5.2.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (3.0.6)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->stellargraph) (2018.9)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->stellargraph) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->stellargraph) (3.0.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.7.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.22.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.37.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.12.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.42.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.10.0.2)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.7.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.7.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.13.3)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (12.0.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1.0->stellargraph) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.8.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.1.1)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"WkC9Wixh5zs6","executionInfo":{"status":"ok","timestamp":1639004826889,"user_tz":300,"elapsed":8,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnCGAjZw512G","executionInfo":{"status":"ok","timestamp":1639004829495,"user_tz":300,"elapsed":1425,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"f0f8c008-4012-492f-be12-6ef8b1d1e1bc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8UE4ARvc58RB","executionInfo":{"status":"ok","timestamp":1639004830998,"user_tz":300,"elapsed":466,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTgBDk0Cy5jl","executionInfo":{"status":"ok","timestamp":1639004836056,"user_tz":300,"elapsed":3702,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["# Import transformers package from huggingface\n","%%capture\n","!pip install transformers\n","\n","from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwjcmi6Q7hY4","executionInfo":{"status":"ok","timestamp":1639004843031,"user_tz":300,"elapsed":3905,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_cased')"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWjx0hYMvvjP"},"source":["# Get the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_m3Xt7Cvw_C","executionInfo":{"status":"ok","timestamp":1639004848670,"user_tz":300,"elapsed":3072,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"e99624d0-e584-4db0-c887-b9a64a1c0ee5"},"source":["from google.colab import drive \n","drive.mount('/content/drive', force_remount = True)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"zcR9XWhYwg91","executionInfo":{"status":"ok","timestamp":1639004854705,"user_tz":300,"elapsed":4726,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["## Read data in\n","df = pd.read_csv('drive/My Drive/Team USA/dataset_corrected.csv')"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxPFeyqVwurW","executionInfo":{"status":"ok","timestamp":1639004856534,"user_tz":300,"elapsed":547,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["train_df = df.loc[:int(0.90*df.shape[0]),:]\n","test_df = df.loc[int(0.90*df.shape[0])+1:,:]\n","len_train = len(train_df)\n","len_test = len(test_df)"],"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#constructing author graph\n","source = ['']\n","target = ['']\n","author_count ={}\n","count = 0\n","for index,row in train_df.iterrows():\n","  # if index == 100000:\n","  #   break\n","  if row['Authors'] is not np.nan and row['Citations'] is not np.nan:\n","    temp = row['Citations'].split(',')\n","    temp2  = row['Authors'].split(',')\n","    for i in temp:\n","      if int(i) <len(train_df):\n","        if train_df.iloc[int(i)]['Authors'] is not np.nan:\n","          temp3 =  train_df.iloc[int(i)]['Authors'].split(',')\n","          list1_permutations =list(itertools.product(temp2,temp3))\n","          for perm in list1_permutations:\n","              if perm[0] in author_count.keys():\n","                author_count[perm[0]]+=1\n","              else:\n","                author_count[perm[0]]=1\n","              if perm[1] in author_count.keys():\n","                author_count[perm[1]]+=1\n","              else:\n","                author_count[perm[1]]=1\n","              source.append(perm[0])\n","              target.append(perm[1])\n","\n","\n","edges = pd.DataFrame(\n","    {\"source\": source, \"target\": target}\n",")\n","values = pd.DataFrame(\n","    {'Count' : author_count.values()}, index = author_count.keys()\n",")"],"metadata":{"id":"JPOUAZnySxpf","executionInfo":{"status":"ok","timestamp":1639005666944,"user_tz":300,"elapsed":267417,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["from stellargraph import StellarGraph\n","Gs = StellarGraph(values, edges)"],"metadata":{"id":"cPiY06JATFV1","executionInfo":{"status":"ok","timestamp":1639006901298,"user_tz":300,"elapsed":1641,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from stellargraph.data import EdgeSplitter\n","# Define an edge splitter on the original graph G:\n","edge_splitter_test = EdgeSplitter(Gs)\n","\n","# Randomly sample a fraction p=0.1 of all positive links, and same number of negative links, from G, and obtain the\n","# reduced graph G_test with the sampled links removed:\n","G_test, edge_ids_test, edge_labels_test = edge_splitter_test.train_test_split(\n","    p=0.1, method=\"global\", keep_connected=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsyramdubHUP","executionInfo":{"status":"ok","timestamp":1639007105223,"user_tz":300,"elapsed":202839,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"6a8e3361-e1f1-4fd1-f726-51bfdafb4cc3"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["** Sampled 323370 positive and 323370 negative edges. **\n"]}]},{"cell_type":"code","metadata":{"id":"8Pma-uU1FoJm","executionInfo":{"status":"ok","timestamp":1639007110405,"user_tz":300,"elapsed":1190,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["Citations_Graph = df['Citations'].dropna().to_dict()\n","citations = [(key, int(value)) for key, values in Citations_Graph.items() for value in values.split(',')]\n","\n","train_citations_graph = train_df['Citations'].dropna().to_dict()\n","test_citations_graph = test_df['Citations'].dropna().to_dict()\n","\n","train_citations = [(key, int(value)) for key, values in train_citations_graph.items() for value in values.split(',') if int(value) < len_train]\n","test_citations = [(key, int(value)) for key, values in test_citations_graph.items() for value in values.split(',') if int(value) > len_train]"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2f1gg6RvxWq"},"source":["# Get the models for the ensemble"]},{"cell_type":"code","metadata":{"id":"3CBbFETdywSr","executionInfo":{"status":"ok","timestamp":1639007112148,"user_tz":300,"elapsed":3,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["class TitleBERT(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.bertTitle = AutoModel.from_pretrained('allenai/scibert_scivocab_cased')\n","    self.linear = nn.Linear(768,1)\n","\n","  def forward(self,inputs):\n","\n","    outs = self.bertTitle(**inputs)\n","    outs = torch.mean(outs['last_hidden_state'],dim = 1)\n","    outs = self.linear(outs)\n","    outs = torch.sigmoid(outs)\n","\n","    return outs\n","\n","class VenueBERT(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.bertVenue = AutoModel.from_pretrained('allenai/scibert_scivocab_cased')\n","    self.linear = nn.Linear(768,1)\n","\n","  def forward(self,inputs):\n","\n","    outs = self.bertVenue(**inputs)\n","    outs = torch.mean(outs['last_hidden_state'],dim = 1)\n","    outs = self.linear(outs)\n","    outs = torch.sigmoid(outs)\n","\n","    return outs\n","\n","class AbstractBERT(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.bertAbstract = AutoModel.from_pretrained('allenai/scibert_scivocab_cased')\n","    self.linear = nn.Linear(768,1)\n","\n","  def forward(self,inputs):\n","\n","    outs = self.bertAbstract(**inputs)\n","    outs = torch.mean(outs['last_hidden_state'],dim = 1)\n","    outs = self.linear(outs)\n","    outs = torch.sigmoid(outs)\n","\n","    return outs"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxZJwTYtv-Dg","executionInfo":{"status":"ok","timestamp":1639007115045,"user_tz":300,"elapsed":2491,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1b1d6c8-899c-442e-cc8e-219022fc61e1"},"source":["# add model paths here to load \n","\n","# titlebert = torch.load('drive/My Drive/Team USA/models/titlebert_patsplit.pth', map_location = torch.device('cpu'))\n","# venuebert = torch.load('drive/My Drive/Team USA/models/venuemodel_kaggle_pat.pth', map_location = torch.device('cpu'))\n","# abstractbert = torch.load('drive/My Drive/Team USA/models/venuemodel_kaggle_pat.pth', map_location = torch.device('cpu'))\n","\n","titlebert = torch.load('drive/My Drive/Team USA/models/titlebert_patsplit.pth')\n","titlebert.to(torch.device('cuda'))\n","venuebert = torch.load('drive/My Drive/Team USA/models/venuemodel_kaggle_pat.pth')\n","venuebert.to(torch.device('cuda'))\n","abstractbert = torch.load('drive/My Drive/Team USA/models/venuemodel_kaggle_pat.pth')\n","abstractbert.to(torch.device('cuda'))"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VenueBERT(\n","  (bertVenue): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31116, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (linear): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTE1kD9Gzgny","executionInfo":{"status":"ok","timestamp":1639007115046,"user_tz":300,"elapsed":13,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"b95a2e8e-f764-4a7b-d516-6d6ced17f407"},"source":["type(titlebert), type(venuebert), type(abstractbert)"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(__main__.TitleBERT, __main__.VenueBERT, __main__.VenueBERT)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"nH2fPUWbzgwN","executionInfo":{"status":"ok","timestamp":1639007115046,"user_tz":300,"elapsed":8,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"source":["# inputs = tokenizer(['ACM Journal 33', 'ACM Journal 33'],['Institute of Manufacturing','ACM Journal 33'],return_tensors='pt',\n","#                     max_length = 32,\n","#                     truncation = True,\n","#                     padding = 'max_length')\n","# titlebert(inputs)\n","# venuebert(inputs)"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["# Dataset and Dataloader"],"metadata":{"id":"XJGiqXKA1SXK"}},{"cell_type":"code","source":["class Citations(Dataset):\n","\n","  def __init__(self,citations,df):\n","    super().__init__()\n","    \n","    self.citations = citations\n","    self.citations_mapping()\n","    self.length = df.shape[0]\n","    self.data = df\n","\n","  def __len__(self):\n","\n","    return len(self.citations)\n","\n","  def citations_mapping(self):\n","    d = {}\n","    for c1, c2 in self.citations:\n","      if c1 not in d:\n","        d[c1] = []\n","      else:\n","        if c2 not in d[c1]:\n","          d[c1].append(c2)\n","    self.d = d\n","\n","  def __getitem__(self,index):\n","\n","    X = []\n","    X.append(self.data.loc[self.citations[index][0],:].values)\n","    X.append(self.data.loc[self.citations[index][0],:].values)\n","   \n","\n","    Y = []\n","    Y.append(self.data.loc[self.citations[index][1],:].values)\n","\n","    # get a random citation that is not part of that paper's citations\n","    rand_cit = self.citations[random.randint(0, len(self.citations)-1)][1]\n","    while rand_cit in self.d[self.citations[index][0]]:\n","      rand_cit = self.citations[random.randint(0, len(self.citations)-1)][1]\n","\n","    Y.append(self.data.loc[rand_cit,:].values)\n","\n","\n","    labels = [1,0]\n","  \n","    return X,Y,labels"],"metadata":{"id":"fQrgKtRu1U1F","executionInfo":{"status":"ok","timestamp":1639007115729,"user_tz":300,"elapsed":4,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["train_dataset = Citations(train_citations, df)\n","test_dataset = Citations(test_citations, df)"],"metadata":{"id":"W1gVU2rN1yLn","executionInfo":{"status":"ok","timestamp":1639007116866,"user_tz":300,"elapsed":2,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohblR9pO-dgQ","executionInfo":{"status":"ok","timestamp":1639007117125,"user_tz":300,"elapsed":5,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"ce5d4fb8-013b-45e1-9384-e85b5c8a247b"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([array([5,\n","         'Interpreting Kullback-Leibler divergence with the Neyman-Pearson lemma',\n","         'Shinto Eguchi,John Copas', 2006,\n","         'Journal of Multivariate Analysis',\n","         'Kullback-Leibler divergence and the Neyman-Pearson lemma are two fundamental concepts in statistics. Both are about likelihood ratios: Kullback-Leibler divergence is the expected log-likelihood ratio, and the Neyman-Pearson lemma is about error rates of likelihood ratio tests. Exploring this connection gives another statistical interpretation of the Kullback-Leibler divergence in terms of the loss of power of the likelihood ratio test when the wrong distribution is used for one of the hypotheses. In this interpretation, the standard non-negativity property of the Kullback-Leibler divergence is essentially a restatement of the optimal property of likelihood ratios established by the Neyman-Pearson lemma. The asymmetry of Kullback-Leibler divergence is overviewed in information geometry.',\n","         '436405'], dtype=object), array([5,\n","         'Interpreting Kullback-Leibler divergence with the Neyman-Pearson lemma',\n","         'Shinto Eguchi,John Copas', 2006,\n","         'Journal of Multivariate Analysis',\n","         'Kullback-Leibler divergence and the Neyman-Pearson lemma are two fundamental concepts in statistics. Both are about likelihood ratios: Kullback-Leibler divergence is the expected log-likelihood ratio, and the Neyman-Pearson lemma is about error rates of likelihood ratio tests. Exploring this connection gives another statistical interpretation of the Kullback-Leibler divergence in terms of the loss of power of the likelihood ratio test when the wrong distribution is used for one of the hypotheses. In this interpretation, the standard non-negativity property of the Kullback-Leibler divergence is essentially a restatement of the optimal property of likelihood ratios established by the Neyman-Pearson lemma. The asymmetry of Kullback-Leibler divergence is overviewed in information geometry.',\n","         '436405'], dtype=object)],\n"," [array([436405, 'Information geometry of U-Boost and Bregman divergence',\n","         'Noboru Murata,Takashi Takenouchi,Takafumi Kanamori,Shinto Eguchi',\n","         2004, 'Neural Computation',\n","         'We aim at an extension of AdaBoost to U-Boost, in the paradigm to build a stronger classification machine from a set of weak learning machines. A geometric understanding of the Bregman divergence defined by a generic convex function U leads to the U-Boost method in the framework of information geometry extended to the space of the finite measures over a label set. We propose two versions of U-Boost learning algorithms by taking account of whether the domain is restricted to the space of probability functions. In the sequential step, we observe that the two adjacent and the initial classifiers are associated with a right triangle in the scale via the Bregman divergence, called the Pythagorean relation. This leads to a mild convergence property of the U-Boost algorithm as seen in the expectation-maximization algorithm. Statistical discussions for consistency and robustness elucidate the properties of the U-Boost methods based on a stochastic assumption for training data.',\n","         '94584,282290,605546,620759,564877,564235,594837,479177,586607'],\n","        dtype=object),\n","  array([216678, 'Static dependent costs for estimating execution time',\n","         'Brian Reistad,David K. Gifford', 1994,\n","         'Proceedings of the 1994 ACM conference on LISP and functional programming',\n","         \"We present the first system for estimating and using data-dependent expression execution times in a language with first-class procedures and imperative constructs. The presence of first-class procedures and imperative constructs makes cost estimation a global problem that can benefit from type information. We estimate expression costs with the aid of an algebraic type reconstruction system that assigns every procedure a type that includes a static dependent cost. A static dependent cost describes the execution time of a procedure in terms of its inputs. In particular, a procedure's static dependent cost can depend on the size of input data structures and the cost of input first-class procedures. Our cost system produces symbolic cost expressions that contain free variables describing the size and cost of the procedure's inputs. At run-time, a cost estimate is dynamically computed from the statically determined cost expression and run-time cost and size information. We present experimental results that validate our cost system on three compilers and architectures. We experimentally demonstrate the utility of cost estimates in making dynamic parallelization decisions. In our experience, dynamic parallelization meets or exceeds the parallel performance of any fixed number of processors.\",\n","         '79620,155289,156096,162949,510662,313666,543908,315120,459150,475349,508491,225124,484756,270347,526313,318161'],\n","        dtype=object)],\n"," [1, 0])"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["train_dataset[0][0][0][2]\n","print(type(train_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"syQrgDQHDLSB","executionInfo":{"status":"ok","timestamp":1639007118352,"user_tz":300,"elapsed":4,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"23f9652e-c105-4039-b644-052ef6759767"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["<class '__main__.Citations'>\n"]}]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"cUwHVqZgQhgE","executionInfo":{"status":"ok","timestamp":1639007119918,"user_tz":300,"elapsed":3,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"xe1_obZqQ8wK","executionInfo":{"status":"ok","timestamp":1639007121027,"user_tz":300,"elapsed":6,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["# Majority voting"],"metadata":{"id":"pYxNXafOD-NP"}},{"cell_type":"code","source":["def rep(s):\n","  if s!=s:\n","    return ' '\n","  else:\n","    return s.split(',')[0]"],"metadata":{"id":"I7d-kAOt-7oH","executionInfo":{"status":"ok","timestamp":1639007122226,"user_tz":300,"elapsed":3,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def custom_collate(batch):\n","\n","  # batch is list of samples : batch = [dataset[0],dataset[1], and so on...]\n","\n","  # lists to store titles and labels\n","  title1, title2, venue1, venue2, abstract1, abstract2 = [], [], [], [], [], []\n","  author1, author2 = [], []\n","  labels = []\n","\n","  for sample in batch:\n","\n","    title1.append(sample[0][0][1])\n","    title1.append(sample[1][0][1])\n","\n","    venue1.append(sample[0][0][4])\n","    venue1.append(sample[0][1][4])\n","\n","    abstract1.append(sample[0][0][5])\n","    abstract1.append(sample[0][1][5])\n","\n","    author1.append(rep(sample[0][0][2]))#.split(',')[0])\n","    author1.append(rep(sample[0][1][2]))#.split(',')[0])\n","\n","    title2.append(sample[1][0][1])\n","    title2.append(sample[1][1][1])\n","\n","    venue2.append(sample[1][0][4])\n","    venue2.append(sample[1][1][4])\n","\n","    abstract2.append(sample[1][0][5])\n","    abstract2.append(sample[1][1][5])\n","\n","    author2.append(rep(sample[1][0][2]))#.split(',')[0])\n","    author2.append(rep(sample[1][1][2]))#.split(',')[0])\n","\n","    labels.extend(sample[2])\n","\n","  return {\"title1\": np.array(title1),\n","          \"title2\": np.array(title2), \n","          \"venue1\": np.array(venue1),\n","          \"venue2\": np.array(venue2),\n","          \"abstract1\":np.array(abstract1),\n","          \"abstract2\": np.array(abstract2),\n","          \"author2\":np.array(author2),\n","          \"author1\":np.array(author1),\n","          \"labels\":labels}"],"metadata":{"id":"3ilNKi1EEyFL","executionInfo":{"status":"ok","timestamp":1639007123354,"user_tz":300,"elapsed":3,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","trainloader = DataLoader(train_dataset, collate_fn = custom_collate, batch_size = BATCH_SIZE, shuffle = False)\n","testloader = DataLoader(test_dataset, collate_fn = custom_collate, batch_size = BATCH_SIZE, shuffle = False)"],"metadata":{"id":"hlU-sw0uHdvX","executionInfo":{"status":"ok","timestamp":1639007123877,"user_tz":300,"elapsed":295,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["import time\n","from tqdm import tqdm\n","from scipy import stats\n","from stellargraph import StellarGraph\n","\n","def isnotnan(s):\n","  return s==s"],"metadata":{"id":"DW0aqJWkLHf2","executionInfo":{"status":"ok","timestamp":1639007125399,"user_tz":300,"elapsed":3,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["stats.mode([0,1])[0][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9HHzTQsT93K","executionInfo":{"status":"ok","timestamp":1639007127505,"user_tz":300,"elapsed":552,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"32fac9c4-61c7-4df5-db28-1622a555d93f"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["graph_model = tf.keras.models.load_model('drive/MyDrive/Team USA/graph_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqrRMZEkMIwL","executionInfo":{"status":"ok","timestamp":1639007130955,"user_tz":300,"elapsed":2479,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"1fac223b-b0ec-4cb1-b890-995ff47b8526"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lagCD0fQNqU6","executionInfo":{"status":"ok","timestamp":1639007132621,"user_tz":300,"elapsed":361,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":["### Majority Voting"],"metadata":{"id":"ide-FGrMbhX5"}},{"cell_type":"code","source":["def compute_accuracy(titlemodel, venuemodel, abstractmodel, graph_model, graph, data_loader, device):\n","    \n","    titlemodel.eval()\n","    venuemodel.eval()\n","    abstractmodel.eval()\n","    # graph_model\n","\n","    with torch.no_grad():\n","\n","        correct_pred, num_examples = 0, 0\n","\n","        for batch_idx, batch in enumerate(data_loader):\n","\n","            print(f\"{batch_idx} of {len(data_loader)}\")\n","\n","            # graph_author_edge = pd.read_csv('drive/MyDrive/edges.csv')\n","            # graph_author_value = pd.read_csv('drive/MyDrive/values.csv') \n","            # Gs = StellarGraph(graph_author_value, graph_author_edge)\n","            test_gen = GraphSAGELinkGenerator(graph, 128, 128)\n","            test_ids = np.column_stack((batch['author1'], batch['author2']))\n","            test_flow = test_gen.flow(test_ids)\n","            # print(len(batch['author1']))\n","            # print(batch['author2'])\n","            # break\n","            start_time = time.time()\n","\n","            ### Prepare data\n","            inputs_title = tokenizer(list(batch['title1']),list(batch['title2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            inputs_venue = tokenizer(list(batch['venue1']),list(batch['venue2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            # print(time.time() - start_time)\n","            \n","            inputs_abstract = tokenizer(list(batch['abstract1']),list(batch['abstract2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            # print(time.time() - start_time)\n","\n","            inputs_title.to(device)\n","            inputs_venue.to(device)\n","            inputs_abstract.to(device)\n","\n","            \n","            labels = torch.Tensor(batch['labels']).view(-1,1).to(device)\n","            \n","            outputs_title = titlemodel(inputs_title)\n","            outputs_venue = venuemodel(inputs_venue)\n","            outputs_abstract = abstractmodel(inputs_abstract)\n","            outputs_graph = graph_model.predict(test_flow)\n","\n","            pred_labels_title = torch.round(outputs_title)\n","            pred_labels_venue = torch.round(outputs_venue)\n","            pred_labels_abstract = torch.round(outputs_abstract)\n","\n","            # determine the locations of the nan features\n","            isnotnan_t = isnotnan(batch['title1']) & isnotnan(batch['title2'])\n","            isnotnan_v = isnotnan(batch['venue1']) & isnotnan(batch['venue2'])\n","            isnotnan_a = isnotnan(batch['abstract1']) & isnotnan(batch['abstract2'])\n","\n","            # print(pred_labels_title)\n","\n","            # -------- Majority Voting (where fields exist) --------------------\n","            pred_labels = []\n","            for i in range(len(batch['title1'])):\n","              res = []\n","              if isnotnan_t[i]:\n","                res.append(pred_labels_title[i].item())\n","              if isnotnan_v[i]:\n","                res.append(pred_labels_venue[i].item())\n","              if isnotnan_a[i]:\n","                res.append(pred_labels_abstract[i].item())\n","\n","              pred_labels.append([stats.mode(res)[0][0]])\n","            pred_labels = torch.Tensor(pred_labels).to(device)\n","            # ---------------------------------------------\n","\n","            # # -------- Averaging (where fields exist) --------------------\n","            # outputs_avg = []\n","            # for i in range(len(batch['title1'])):\n","            #   res = []\n","            #   if isnotnan_t[i]:\n","            #     res.append(outputs_title[i].item())\n","            #   if isnotnan_v[i]:\n","            #     res.append(outputs_venue[i].item())\n","            #   if isnotnan_a[i]:\n","            #     res.append(outputs_abstract[i].item())\n","\n","            #   outputs_avg.append([np.mean(res)])\n","            # outputs_avg = torch.Tensor(outputs_avg).to(device)\n","            # pred_labels = torch.round(outputs_avg)\n","            # # ---------------------------------------------\n","\n","            # print(pred_labels)\n","            # print(labels)\n","\n","            num_examples += labels.size(0)\n","\n","            correct_pred += (pred_labels == labels).sum()\n","\n","            print(correct_pred.float()/num_examples * 100)\n","    return correct_pred.float()/num_examples * 100"],"metadata":{"id":"UcZjOrFMEAJa","executionInfo":{"status":"ok","timestamp":1639007136766,"user_tz":300,"elapsed":609,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# compute_accuracy(titlebert, venuebert, abstractbert, trainloader, 'cpu')\n","compute_accuracy(titlebert, venuebert, abstractbert,graph_model, G_test, trainloader, 'cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7wkHx24uISpv","executionInfo":{"status":"error","timestamp":1639007145694,"user_tz":300,"elapsed":1313,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}},"outputId":"e35d27a7-0c85-48a6-9aed-443c5ba9e7aa"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["0 of 7879\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-e7ead61c9a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute_accuracy(titlebert, venuebert, abstractbert, trainloader, 'cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitlebert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvenuebert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstractbert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-69-09f6087a29fe>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(titlemodel, venuemodel, abstractmodel, graph_model, graph, data_loader, device)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0moutputs_venue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvenuemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_venue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0moutputs_abstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstractmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_abstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moutputs_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_flow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mpred_labels_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/mapper/sequences.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, batch_num)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Get node features for batch of link ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mbatch_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/mapper/sampled_link_generators.py\u001b[0m in \u001b[0;36msample_features\u001b[0;34m(self, head_links, batch_num)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhead_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             node_samples = self._samplers[batch_num].run(\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             )\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/data/explorer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nodes, n_size, n, seed, weighted)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlists\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mlist\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mids\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBFW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \"\"\"\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_common_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mpy_and_np_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/data/explorer.py\u001b[0m in \u001b[0;36m_check_sizes\u001b[0;34m(self, n_size)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The neighbourhood size must be a list of non-negative integers.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Technically, length 0 should be okay, but by consensus it is invalid.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/data/explorer.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"({}) {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_common_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: (SampledBreadthFirstWalk) The neighbourhood size must be a list of non-negative integers."]}]},{"cell_type":"code","source":["# compute_accuracy(titlebert, venuebert, abstractbert, testloader, 'cpu')\n","compute_accuracy(titlebert, venuebert, abstractbert, testloader, 'cuda')"],"metadata":{"id":"Xphc04rWMuG4","executionInfo":{"status":"aborted","timestamp":1639007145692,"user_tz":300,"elapsed":9,"user":{"displayName":"Aadarsh Pratik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03237641131224762207"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Average ensemble"],"metadata":{"id":"V0cm5hDFbj_6"}},{"cell_type":"code","source":["def compute_accuracy(titlemodel, venuemodel, abstractmodel, data_loader, device):\n","    \n","    titlemodel.eval()\n","    venuemodel.eval()\n","    abstractmodel.eval()\n","\n","    with torch.no_grad():\n","\n","        correct_pred, num_examples = 0, 0\n","\n","        for batch_idx, batch in enumerate(data_loader):\n","\n","            print(f\"{batch_idx} of {len(data_loader)}\")\n","\n","            # print(batch['venue1'])\n","            \n","\n","            start_time = time.time()\n","\n","            ### Prepare data\n","            inputs_title = tokenizer(list(batch['title1']),list(batch['title2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            inputs_venue = tokenizer(list(batch['venue1']),list(batch['venue2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            # print(time.time() - start_time)\n","            \n","            inputs_abstract = tokenizer(list(batch['abstract1']),list(batch['abstract2']),return_tensors='pt',\n","                    max_length = 32,\n","                    truncation = True,\n","                    padding = 'max_length')\n","            \n","            # print(time.time() - start_time)\n","\n","            inputs_title.to(device)\n","            inputs_venue.to(device)\n","            inputs_abstract.to(device)\n","\n","            \n","            labels = torch.Tensor(batch['labels']).view(-1,1).to(device)\n","            \n","            outputs_title = titlemodel(inputs_title)\n","            outputs_venue = venuemodel(inputs_venue)\n","            outputs_abstract = abstractmodel(inputs_abstract)\n","\n","            pred_labels_title = torch.round(outputs_title)\n","            pred_labels_venue = torch.round(outputs_venue)\n","            pred_labels_abstract = torch.round(outputs_abstract)\n","\n","            # determine the locations of the nan features\n","            isnotnan_t = isnotnan(batch['title1']) & isnotnan(batch['title2'])\n","            isnotnan_v = isnotnan(batch['venue1']) & isnotnan(batch['venue2'])\n","            isnotnan_a = isnotnan(batch['abstract1']) & isnotnan(batch['abstract2'])\n","\n","            # print(pred_labels_title)\n","\n","            # # -------- Majority Voting (where fields exist) --------------------\n","            # pred_labels = []\n","            # for i in range(len(batch['title1'])):\n","            #   res = []\n","            #   if isnotnan_t[i]:\n","            #     res.append(pred_labels_title[i].item())\n","            #   if isnotnan_v[i]:\n","            #     res.append(pred_labels_venue[i].item())\n","            #   if isnotnan_a[i]:\n","            #     res.append(pred_labels_abstract[i].item())\n","\n","            #   pred_labels.append([stats.mode(res)[0][0]])\n","            # pred_labels = torch.Tensor(pred_labels).to(device)\n","            # # ---------------------------------------------\n","\n","            # -------- Averaging (where fields exist) --------------------\n","            outputs_avg = []\n","            for i in range(len(batch['title1'])):\n","              res = []\n","              if isnotnan_t[i]:\n","                res.append(outputs_title[i].item())\n","              if isnotnan_v[i]:\n","                res.append(outputs_venue[i].item())\n","              if isnotnan_a[i]:\n","                res.append(outputs_abstract[i].item())\n","\n","              outputs_avg.append([np.mean(res)])\n","            outputs_avg = torch.Tensor(outputs_avg).to(device)\n","            pred_labels = torch.round(outputs_avg)\n","            # ---------------------------------------------\n","\n","            # print(pred_labels)\n","            # print(labels)\n","\n","            num_examples += labels.size(0)\n","\n","            correct_pred += (pred_labels == labels).sum()\n","\n","            print(correct_pred.float()/num_examples * 100)\n","    return correct_pred.float()/num_examples * 100"],"metadata":{"id":"pKskpx5pbmLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute_accuracy(titlebert, venuebert, abstractbert, testloader, 'cpu')\n","compute_accuracy(titlebert, venuebert, abstractbert, testloader, 'cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUmEBkGabsBU","executionInfo":{"status":"ok","timestamp":1638990519930,"user_tz":300,"elapsed":215618,"user":{"displayName":"Sanjan Das","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07423016562538290108"}},"outputId":"2941db51-ca8f-4b04-eeb6-e1803fff0d0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 of 128\n","tensor(81.2500, device='cuda:0')\n","1 of 128\n","tensor(82.8125, device='cuda:0')\n","2 of 128\n","tensor(83.0729, device='cuda:0')\n","3 of 128\n","tensor(82.6172, device='cuda:0')\n","4 of 128\n","tensor(81.2500, device='cuda:0')\n","5 of 128\n","tensor(80.8594, device='cuda:0')\n","6 of 128\n","tensor(80.4688, device='cuda:0')\n","7 of 128\n","tensor(79.8828, device='cuda:0')\n","8 of 128\n","tensor(79.8611, device='cuda:0')\n","9 of 128\n","tensor(80.2344, device='cuda:0')\n","10 of 128\n","tensor(80.1136, device='cuda:0')\n","11 of 128\n","tensor(80.4688, device='cuda:0')\n","12 of 128\n","tensor(80.7091, device='cuda:0')\n","13 of 128\n","tensor(80.4129, device='cuda:0')\n","14 of 128\n","tensor(80.3125, device='cuda:0')\n","15 of 128\n","tensor(79.9805, device='cuda:0')\n","16 of 128\n","tensor(80.3309, device='cuda:0')\n","17 of 128\n","tensor(80.0347, device='cuda:0')\n","18 of 128\n","tensor(79.9342, device='cuda:0')\n","19 of 128\n","tensor(79.6094, device='cuda:0')\n","20 of 128\n","tensor(79.5759, device='cuda:0')\n","21 of 128\n","tensor(79.7940, device='cuda:0')\n","22 of 128\n","tensor(80.1291, device='cuda:0')\n","23 of 128\n","tensor(80.0456, device='cuda:0')\n","24 of 128\n","tensor(80.1875, device='cuda:0')\n","25 of 128\n","tensor(80.2284, device='cuda:0')\n","26 of 128\n","tensor(80.2951, device='cuda:0')\n","27 of 128\n","tensor(79.9944, device='cuda:0')\n","28 of 128\n","tensor(80.0377, device='cuda:0')\n","29 of 128\n","tensor(80.0781, device='cuda:0')\n","30 of 128\n","tensor(80.1411, device='cuda:0')\n","31 of 128\n","tensor(80.2979, device='cuda:0')\n","32 of 128\n","tensor(80.3977, device='cuda:0')\n","33 of 128\n","tensor(80.4458, device='cuda:0')\n","34 of 128\n","tensor(80.3795, device='cuda:0')\n","35 of 128\n","tensor(80.2734, device='cuda:0')\n","36 of 128\n","tensor(80.2576, device='cuda:0')\n","37 of 128\n","tensor(80.2015, device='cuda:0')\n","38 of 128\n","tensor(80.2885, device='cuda:0')\n","39 of 128\n","tensor(80.1367, device='cuda:0')\n","40 of 128\n","tensor(80.0495, device='cuda:0')\n","41 of 128\n","tensor(79.9479, device='cuda:0')\n","42 of 128\n","tensor(79.9964, device='cuda:0')\n","43 of 128\n","tensor(80.0071, device='cuda:0')\n","44 of 128\n","tensor(79.9653, device='cuda:0')\n","45 of 128\n","tensor(79.8743, device='cuda:0')\n","46 of 128\n","tensor(79.7706, device='cuda:0')\n","47 of 128\n","tensor(79.6875, device='cuda:0')\n","48 of 128\n","tensor(79.6716, device='cuda:0')\n","49 of 128\n","tensor(79.6406, device='cuda:0')\n","50 of 128\n","tensor(79.5803, device='cuda:0')\n","51 of 128\n","tensor(79.5523, device='cuda:0')\n","52 of 128\n","tensor(79.5991, device='cuda:0')\n","53 of 128\n","tensor(79.4994, device='cuda:0')\n","54 of 128\n","tensor(79.4460, device='cuda:0')\n","55 of 128\n","tensor(79.4364, device='cuda:0')\n","56 of 128\n","tensor(79.4408, device='cuda:0')\n","57 of 128\n","tensor(79.2969, device='cuda:0')\n","58 of 128\n","tensor(79.1843, device='cuda:0')\n","59 of 128\n","tensor(79.1667, device='cuda:0')\n","60 of 128\n","tensor(79.1240, device='cuda:0')\n","61 of 128\n","tensor(79.0575, device='cuda:0')\n","62 of 128\n","tensor(79.0179, device='cuda:0')\n","63 of 128\n","tensor(79.0527, device='cuda:0')\n","64 of 128\n","tensor(79.0505, device='cuda:0')\n","65 of 128\n","tensor(79.0483, device='cuda:0')\n","66 of 128\n","tensor(78.9995, device='cuda:0')\n","67 of 128\n","tensor(79.0556, device='cuda:0')\n","68 of 128\n","tensor(79.0195, device='cuda:0')\n","69 of 128\n","tensor(79.0067, device='cuda:0')\n","70 of 128\n","tensor(78.9613, device='cuda:0')\n","71 of 128\n","tensor(78.9605, device='cuda:0')\n","72 of 128\n","tensor(78.9705, device='cuda:0')\n","73 of 128\n","tensor(78.9485, device='cuda:0')\n","74 of 128\n","tensor(79.0104, device='cuda:0')\n","75 of 128\n","tensor(79.0193, device='cuda:0')\n","76 of 128\n","tensor(79.1092, device='cuda:0')\n","77 of 128\n","tensor(79.1166, device='cuda:0')\n","78 of 128\n","tensor(79.1535, device='cuda:0')\n","79 of 128\n","tensor(79.1113, device='cuda:0')\n","80 of 128\n","tensor(79.1570, device='cuda:0')\n","81 of 128\n","tensor(79.1825, device='cuda:0')\n","82 of 128\n","tensor(79.2075, device='cuda:0')\n","83 of 128\n","tensor(79.2039, device='cuda:0')\n","84 of 128\n","tensor(79.2004, device='cuda:0')\n","85 of 128\n","tensor(79.1515, device='cuda:0')\n","86 of 128\n","tensor(79.1307, device='cuda:0')\n","87 of 128\n","tensor(79.1282, device='cuda:0')\n","88 of 128\n","tensor(79.1345, device='cuda:0')\n","89 of 128\n","tensor(79.0885, device='cuda:0')\n","90 of 128\n","tensor(79.1037, device='cuda:0')\n","91 of 128\n","tensor(79.1101, device='cuda:0')\n","92 of 128\n","tensor(79.1163, device='cuda:0')\n","93 of 128\n","tensor(79.1390, device='cuda:0')\n","94 of 128\n","tensor(79.0789, device='cuda:0')\n","95 of 128\n","tensor(79.0446, device='cuda:0')\n","96 of 128\n","tensor(78.9868, device='cuda:0')\n","97 of 128\n","tensor(79.0179, device='cuda:0')\n","98 of 128\n","tensor(79.0246, device='cuda:0')\n","99 of 128\n","tensor(79.0312, device='cuda:0')\n","100 of 128\n","tensor(78.9913, device='cuda:0')\n","101 of 128\n","tensor(79.0058, device='cuda:0')\n","102 of 128\n","tensor(79.0200, device='cuda:0')\n","103 of 128\n","tensor(78.9588, device='cuda:0')\n","104 of 128\n","tensor(78.9509, device='cuda:0')\n","105 of 128\n","tensor(79.0168, device='cuda:0')\n","106 of 128\n","tensor(79.0304, device='cuda:0')\n","107 of 128\n","tensor(79.0148, device='cuda:0')\n","108 of 128\n","tensor(79.0783, device='cuda:0')\n","109 of 128\n","tensor(79.0767, device='cuda:0')\n","110 of 128\n","tensor(79.0963, device='cuda:0')\n","111 of 128\n","tensor(79.0737, device='cuda:0')\n","112 of 128\n","tensor(79.0860, device='cuda:0')\n","113 of 128\n","tensor(79.0844, device='cuda:0')\n","114 of 128\n","tensor(79.1100, device='cuda:0')\n","115 of 128\n","tensor(79.1016, device='cuda:0')\n","116 of 128\n","tensor(79.1333, device='cuda:0')\n","117 of 128\n","tensor(79.1446, device='cuda:0')\n","118 of 128\n","tensor(79.1295, device='cuda:0')\n","119 of 128\n","tensor(79.1536, device='cuda:0')\n","120 of 128\n","tensor(79.1710, device='cuda:0')\n","121 of 128\n","tensor(79.1944, device='cuda:0')\n","122 of 128\n","tensor(79.2302, device='cuda:0')\n","123 of 128\n","tensor(79.2339, device='cuda:0')\n","124 of 128\n","tensor(79.2188, device='cuda:0')\n","125 of 128\n","tensor(79.2411, device='cuda:0')\n","126 of 128\n","tensor(79.2446, device='cuda:0')\n","127 of 128\n","tensor(79.2290, device='cuda:0')\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(79.2290, device='cuda:0')"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"17kl-rTdv-vE"},"source":["# Run a forward pass on sample input"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VK1Wt-QE--IJ","executionInfo":{"status":"ok","timestamp":1638914078348,"user_tz":300,"elapsed":3079,"user":{"displayName":"Sanjan Das","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07423016562538290108"}},"outputId":"23703770-8dc3-4788-eb62-31e05fa2646b"},"source":["ind = 17 \n","p1 = df.iloc[17]\n","\n","cits = df['Citations'][ind]\n","cits = cits.split(',')\n","cits = [int(c) for c in cits]\n","\n","for c in cits:\n","  print(c)\n","  p2 = df.iloc[c]\n","  \n","  inputs_title = tokenizer([p1['Title']], [p2['Title']], return_tensors = 'pt',\n","                           max_length = 32, truncation = True, padding = 'max_length')\n","  print(titlebert(inputs_title))\n","  \n","  if type(p1['Venue'])==str and type(p2['Venue'])==str:\n","    inputs_venue = tokenizer([p1['Venue']], [p2['Venue']], return_tensors = 'pt',\n","                            max_length = 32, truncation = True, padding = 'max_length')\n","    print(venuebert(inputs_venue))\n","  \n","  \n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["357875\n","tensor([[0.9623]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.6248]], grad_fn=<SigmoidBackward0>)\n","214023\n","tensor([[0.9941]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.9963]], grad_fn=<SigmoidBackward0>)\n","317448\n","tensor([[0.9946]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.9956]], grad_fn=<SigmoidBackward0>)\n","319987\n","tensor([[0.9871]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.6522]], grad_fn=<SigmoidBackward0>)\n","334185\n","tensor([[0.9861]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.7613]], grad_fn=<SigmoidBackward0>)\n","95255\n","tensor([[0.9748]], grad_fn=<SigmoidBackward0>)\n","294124\n","tensor([[0.3765]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.8313]], grad_fn=<SigmoidBackward0>)\n","96319\n","tensor([[0.0501]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.1989]], grad_fn=<SigmoidBackward0>)\n","610127\n","tensor([[0.9993]], grad_fn=<SigmoidBackward0>)\n","tensor([[0.9962]], grad_fn=<SigmoidBackward0>)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XV2-wgbyHkXz","executionInfo":{"status":"ok","timestamp":1638818415270,"user_tz":300,"elapsed":26603,"user":{"displayName":"Sanjan Das","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07423016562538290108"}},"outputId":"9c06597c-ca35-434e-fb11-44f3e53aa564"},"source":["# Averaging ensemble\n","\n","prob = []\n","\n","for idx1, idx2 in tqdm(test_citations):\n","\n","  # get the two papers\n","  p1 = df.iloc[idx1]\n","  p2 = df.iloc[idx2]\n","\n","  res = []\n","\n","  # title will always exist (I think??)\n","  inputs_title = tokenizer([p1['Title']], [p2['Title']], return_tensors = 'pt',\n","                           max_length = 32, truncation = True, padding = 'max_length')\n","  res.append(titlebert(inputs_title).item())\n","  \n","  if type(p1['Venue'])==str and type(p2['Venue'])==str:\n","    inputs_venue = tokenizer([p1['Venue']], [p2['Venue']], return_tensors = 'pt',\n","                            max_length = 32, truncation = True, padding = 'max_length')\n","    # print(venuebert(inputs_venue))\n","    res.append(venuebert(inputs_venue).item())\n","\n","  prob.append(np.mean(res))\n","  # print(np.mean(res))\n","\n","\n","\n","print(prob)\n","\n","  \n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.9102713167667389, 0.4544652998447418, 0.5327351689338684, 0.7293183207511902, 0.7384950518608093, 0.858288586139679, 0.9193280339241028, 0.9970178604125977, 0.9317418038845062, 0.8895634710788727, 0.8271278142929077, 0.757253110408783, 0.8239882290363312, 0.665449246764183, 0.14407627284526825, 0.9084127843379974, 0.9106732308864594, 0.9390210807323456, 0.22672046720981598, 0.979086697101593, 0.9682144522666931, 0.5376552641391754, 0.394911527633667, 0.8768737018108368, 0.6421718597412109, 0.999293327331543, 0.6416687965393066, 0.5108339190483093, 0.7773755490779877, 0.9958547949790955, 0.6665770411491394, 0.9948846697807312, 0.9737203121185303, 0.9745980501174927, 0.994413435459137, 0.8615728914737701, 0.9912108182907104, 0.999254047870636, 0.939901202917099, 0.8948940634727478, 0.9845825433731079, 0.9923205971717834, 0.9995452761650085, 0.9937540888786316, 0.5401720404624939, 0.9878716468811035, 0.9829439520835876, 0.9723591208457947, 0.8204454481601715, 0.9447020590305328, 0.8528525233268738, 0.5663111582398415, 0.6077004000544548, 0.9168221354484558, 0.95426145195961, 0.39509070850908756, 0.9903683662414551, 0.6379919499158859, 0.9021595120429993, 0.9915938377380371, 0.6260009258985519, 0.9696681201457977, 0.40560929477214813, 0.6954577416181564, 0.99442058801651, 0.5097854752093554, 0.9287169575691223, 0.9812765717506409, 0.9502677321434021, 0.09900073707103729, 0.685314729809761, 0.9934592247009277, 0.9979805946350098, 0.5961407870054245, 0.9507759809494019, 0.977055549621582, 0.9961181879043579, 0.5923318415880203, 0.8571091890335083, 0.9964445233345032, 0.7648801803588867, 0.6495733559131622, 0.573954813182354, 0.7429214715957642, 0.5801458284258842, 0.986804723739624, 0.8877615034580231, 0.8903950452804565, 0.8823361992835999, 0.8088386356830597, 0.7688975930213928, 0.13555806875228882, 0.8926053047180176, 0.9977233409881592, 0.9973711967468262, 0.9360950589179993, 0.6110357344150543, 0.9885904788970947, 0.6755042970180511, 0.4039379358291626, 0.6880935728549957]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zxxgwxdBTOG","executionInfo":{"status":"ok","timestamp":1638818415663,"user_tz":300,"elapsed":7,"user":{"displayName":"Sanjan Das","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07423016562538290108"}},"outputId":"7d41c188-0a1c-47ea-8ee4-ad3e73e446da"},"source":["np.mean(prob)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7968190245625406"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"_0FZZ-gS_ZHU"},"source":[""],"execution_count":null,"outputs":[]}]}